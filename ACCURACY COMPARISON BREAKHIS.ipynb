{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "846d490b-3e17-4fdf-ba30-306f91676408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import EfficientNetB0, Xception\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2985bdd2-1d00-4394-8002-ac40e7582231",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "SEED = 42\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbf7d32d-f808-461d-8e98-cc7d2fed05f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df = pd.read_csv(\"BreakHis\\labels.csv\")\n",
    "eff_kmeans_df = pd.read_csv(\"EfficientNetB0_KMeans.csv\")\n",
    "\n",
    "# If you have Xception-Birch file:\n",
    "xcep_birch_df = pd.read_csv(\"Xception_Birch.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aafdad5-86b6-4c49-b9ab-c897de0187d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df, label_column):\n",
    "\n",
    "    df = df.copy()\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    df[\"label_encoded\"] = le.fit_transform(df[label_column])\n",
    "\n",
    "    num_classes = df[\"label_encoded\"].nunique()\n",
    "\n",
    "    X = df[\"image_name\"].values\n",
    "    y = to_categorical(df[\"label_encoded\"], num_classes)\n",
    "\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y,\n",
    "        test_size=0.3,\n",
    "        random_state=SEED,\n",
    "        stratify=df[\"label_encoded\"]\n",
    "    )\n",
    "\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp,\n",
    "        test_size=0.5,\n",
    "        random_state=SEED\n",
    "    )\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test, num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e6897af-bec7-4d5c-8fd0-4a5ce53c4855",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "MIXED_FOLDER = \"BreakHis\\mixed_images\"   \n",
    "\n",
    "def load_image(image_name):\n",
    "    full_path = os.path.join(MIXED_FOLDER, image_name)\n",
    "\n",
    "    img = tf.keras.preprocessing.image.load_img(\n",
    "        full_path,\n",
    "        target_size=(IMG_SIZE, IMG_SIZE)\n",
    "    )\n",
    "    img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "\n",
    "def create_dataset(X, y):\n",
    "    images = np.array([load_image(name) for name in X])\n",
    "    return images, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b066966e-ba5b-4a9a-8a74-6540f985c291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_efficientnet(num_classes):\n",
    "\n",
    "    base = EfficientNetB0(\n",
    "        weights=None,            # NO pretrained\n",
    "        include_top=False,\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "    )\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base.output)\n",
    "    output = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=base.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4309ea38-30c5-4a30-8920-3c799f83d40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_xception(num_classes):\n",
    "\n",
    "    base = Xception(\n",
    "        weights=None,           # NO pretrained\n",
    "        include_top=False,\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "    )\n",
    "\n",
    "    x = GlobalAveragePooling2D()(base.output)\n",
    "    output = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=base.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b71004f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['image_name', 'class', 'tumor_type', 'magnification'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(original_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b188eb20-2d16-46a1-bdd0-301dfdd8ea9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m241s\u001b[0m 1s/step - accuracy: 0.7814 - loss: 0.5392 - val_accuracy: 0.6847 - val_loss: 1.2481\n",
      "Epoch 2/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 1s/step - accuracy: 0.8452 - loss: 0.3743 - val_accuracy: 0.6847 - val_loss: 0.9314\n",
      "Epoch 3/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 1s/step - accuracy: 0.8568 - loss: 0.3390 - val_accuracy: 0.6847 - val_loss: 2.6158\n",
      "Epoch 4/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m221s\u001b[0m 1s/step - accuracy: 0.8770 - loss: 0.2840 - val_accuracy: 0.4705 - val_loss: 1.2357\n",
      "Epoch 5/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 1s/step - accuracy: 0.8943 - loss: 0.2542 - val_accuracy: 0.7015 - val_loss: 1.1312\n",
      "Epoch 6/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 1s/step - accuracy: 0.9142 - loss: 0.2132 - val_accuracy: 0.4722 - val_loss: 1.8335\n",
      "Epoch 7/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 1s/step - accuracy: 0.9286 - loss: 0.1816 - val_accuracy: 0.7563 - val_loss: 0.6560\n",
      "Epoch 8/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 1s/step - accuracy: 0.9426 - loss: 0.1440 - val_accuracy: 0.7159 - val_loss: 1.7376\n",
      "Epoch 9/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 1s/step - accuracy: 0.9538 - loss: 0.1214 - val_accuracy: 0.8019 - val_loss: 0.5734\n",
      "Epoch 10/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 1s/step - accuracy: 0.9621 - loss: 0.1074 - val_accuracy: 0.7875 - val_loss: 0.6449\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 181ms/step - accuracy: 0.7801 - loss: 0.6844\n",
      "EfficientNet trained on ORIGINAL labels Accuracy: 0.780117928981781\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test, num_classes = prepare_data(original_df,\"class\")\n",
    "\n",
    "X_train_img, y_train = create_dataset(X_train, y_train)\n",
    "X_val_img, y_val = create_dataset(X_val, y_val)\n",
    "X_test_img, y_test = create_dataset(X_test, y_test)\n",
    "\n",
    "model_eff_original = build_efficientnet(num_classes)\n",
    "\n",
    "model_eff_original.fit(\n",
    "    X_train_img, y_train,\n",
    "    validation_data=(X_val_img, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "loss1, acc1 = model_eff_original.evaluate(X_test_img, y_test)\n",
    "print(\"EfficientNet trained on ORIGINAL labels Accuracy:\", acc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c886d688-7966-4f2a-9dc5-c1d325f211e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m236s\u001b[0m 1s/step - accuracy: 0.9090 - loss: 0.2906 - val_accuracy: 0.9275 - val_loss: 0.3722\n",
      "Epoch 2/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 1s/step - accuracy: 0.9207 - loss: 0.1763 - val_accuracy: 0.9275 - val_loss: 0.4959\n",
      "Epoch 3/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 1s/step - accuracy: 0.9268 - loss: 0.1612 - val_accuracy: 0.9275 - val_loss: 0.4504\n",
      "Epoch 4/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 1s/step - accuracy: 0.9353 - loss: 0.1454 - val_accuracy: 0.9275 - val_loss: 0.2153\n",
      "Epoch 5/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 1s/step - accuracy: 0.9398 - loss: 0.1358 - val_accuracy: 0.9570 - val_loss: 0.1145\n",
      "Epoch 6/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 1s/step - accuracy: 0.9433 - loss: 0.1330 - val_accuracy: 0.9553 - val_loss: 0.1235\n",
      "Epoch 7/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 1s/step - accuracy: 0.9361 - loss: 0.1464 - val_accuracy: 0.8179 - val_loss: 0.4094\n",
      "Epoch 8/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 1s/step - accuracy: 0.9465 - loss: 0.1295 - val_accuracy: 0.8845 - val_loss: 0.2491\n",
      "Epoch 9/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 1s/step - accuracy: 0.9577 - loss: 0.1072 - val_accuracy: 0.4317 - val_loss: 0.9578\n",
      "Epoch 10/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 1s/step - accuracy: 0.9554 - loss: 0.1125 - val_accuracy: 0.9115 - val_loss: 0.2411\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 183ms/step - accuracy: 0.9082 - loss: 0.2590\n",
      "\n",
      "EfficientNet trained on KMeans labels Accuracy: 0.9081718325614929\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test, num_classes = prepare_data(\n",
    "    eff_kmeans_df,\n",
    "    label_column=\"cluster_label\"   # <-- adjust if needed\n",
    ")\n",
    "\n",
    "X_train_img, y_train = create_dataset(X_train, y_train)\n",
    "X_val_img, y_val = create_dataset(X_val, y_val)\n",
    "X_test_img, y_test = create_dataset(X_test, y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_eff_cluster = build_efficientnet(num_classes)\n",
    "\n",
    "model_eff_cluster.fit(\n",
    "    X_train_img, y_train,\n",
    "    validation_data=(X_val_img, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "loss2, acc2 = model_eff_cluster.evaluate(X_test_img, y_test)\n",
    "\n",
    "print(\"\\nEfficientNet trained on KMeans labels Accuracy:\", acc2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3161b3ac-2ac2-4153-9c18-c2c9fd0bfb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 2s/step - accuracy: 0.8174 - loss: 0.4442 - val_accuracy: 0.6847 - val_loss: 0.6465\n",
      "Epoch 2/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 2s/step - accuracy: 0.8595 - loss: 0.3314 - val_accuracy: 0.6847 - val_loss: 0.6147\n",
      "Epoch 3/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 2s/step - accuracy: 0.8687 - loss: 0.3049 - val_accuracy: 0.7074 - val_loss: 0.7351\n",
      "Epoch 4/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 2s/step - accuracy: 0.8848 - loss: 0.2674 - val_accuracy: 0.7799 - val_loss: 0.7816\n",
      "Epoch 5/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m422s\u001b[0m 2s/step - accuracy: 0.8983 - loss: 0.2386 - val_accuracy: 0.7420 - val_loss: 1.2816\n",
      "Epoch 6/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m422s\u001b[0m 2s/step - accuracy: 0.9079 - loss: 0.2216 - val_accuracy: 0.6872 - val_loss: 5.3573\n",
      "Epoch 7/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m422s\u001b[0m 2s/step - accuracy: 0.9214 - loss: 0.2007 - val_accuracy: 0.8592 - val_loss: 0.3836\n",
      "Epoch 8/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 2s/step - accuracy: 0.9259 - loss: 0.1874 - val_accuracy: 0.8373 - val_loss: 1.1297\n",
      "Epoch 9/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m422s\u001b[0m 2s/step - accuracy: 0.9294 - loss: 0.1735 - val_accuracy: 0.8777 - val_loss: 0.3961\n",
      "Epoch 10/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 2s/step - accuracy: 0.9386 - loss: 0.1549 - val_accuracy: 0.7749 - val_loss: 1.5085\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 492ms/step - accuracy: 0.7700 - loss: 1.3243\n",
      "\n",
      "Xception trained on ORIGINAL labels Accuracy: 0.7700084447860718\n"
     ]
    }
   ],
   "source": [
    "# Prepare data (original labels)\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, num_classes = prepare_data(\n",
    "    original_df,\n",
    "    label_column=\"class\"   # original label column\n",
    ")\n",
    "\n",
    "X_train_img, y_train = create_dataset(X_train, y_train)\n",
    "X_val_img, y_val = create_dataset(X_val, y_val)\n",
    "X_test_img, y_test = create_dataset(X_test, y_test)\n",
    "\n",
    "# Build model\n",
    "model_x_original = build_xception(num_classes)\n",
    "\n",
    "# Train\n",
    "model_x_original.fit(\n",
    "    X_train_img, y_train,\n",
    "    validation_data=(X_val_img, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "loss3, acc3 = model_x_original.evaluate(X_test_img, y_test)\n",
    "\n",
    "print(\"\\nXception trained on ORIGINAL labels Accuracy:\", acc3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36a175b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m441s\u001b[0m 2s/step - accuracy: 0.7820 - loss: 0.4960 - val_accuracy: 0.3744 - val_loss: 0.6934\n",
      "Epoch 2/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 2s/step - accuracy: 0.8212 - loss: 0.3769 - val_accuracy: 0.6256 - val_loss: 0.7479\n",
      "Epoch 3/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m407s\u001b[0m 2s/step - accuracy: 0.8304 - loss: 0.3663 - val_accuracy: 0.6256 - val_loss: 1.2099\n",
      "Epoch 4/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 2s/step - accuracy: 0.8405 - loss: 0.3418 - val_accuracy: 0.7184 - val_loss: 1.1649\n",
      "Epoch 5/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 2s/step - accuracy: 0.8524 - loss: 0.3249 - val_accuracy: 0.7057 - val_loss: 1.1122\n",
      "Epoch 6/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 2s/step - accuracy: 0.8591 - loss: 0.3121 - val_accuracy: 0.5658 - val_loss: 2.2141\n",
      "Epoch 7/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 3s/step - accuracy: 0.8605 - loss: 0.3092 - val_accuracy: 0.6619 - val_loss: 1.2786\n",
      "Epoch 8/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m444s\u001b[0m 3s/step - accuracy: 0.8669 - loss: 0.3049 - val_accuracy: 0.8153 - val_loss: 2.0162\n",
      "Epoch 9/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 3s/step - accuracy: 0.8705 - loss: 0.2844 - val_accuracy: 0.8255 - val_loss: 0.3775\n",
      "Epoch 10/10\n",
      "\u001b[1m173/173\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 3s/step - accuracy: 0.8746 - loss: 0.2847 - val_accuracy: 0.4528 - val_loss: 13.7894\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 523ms/step - accuracy: 0.4676 - loss: 14.2295\n",
      "\n",
      "Xception trained on Birch labels Accuracy: 0.46756529808044434\n"
     ]
    }
   ],
   "source": [
    "# Prepare data (Birch cluster labels)\n",
    "\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, num_classes = prepare_data(\n",
    "    xcep_birch_df,\n",
    "    label_column=\"cluster_label\"   # <-- change if different\n",
    ")\n",
    "\n",
    "X_train_img, y_train = create_dataset(X_train, y_train)\n",
    "X_val_img, y_val = create_dataset(X_val, y_val)\n",
    "X_test_img, y_test = create_dataset(X_test, y_test)\n",
    "\n",
    "# Build model\n",
    "model_x_cluster = build_xception(num_classes)\n",
    "\n",
    "# Train\n",
    "model_x_cluster.fit(\n",
    "    X_train_img, y_train,\n",
    "    validation_data=(X_val_img, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "loss4, acc4 = model_x_cluster.evaluate(X_test_img, y_test)\n",
    "\n",
    "print(\"\\nXception trained on Birch labels Accuracy:\", acc4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "938c1dd8-44ad-4d7d-8784-3aaf1f6beafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== FINAL RESULTS ==========\n",
      "EfficientNet Original Accuracy: 0.780117928981781\n",
      "EfficientNet Cluster Accuracy : 0.9081718325614929\n",
      "Xception Original Accuracy    : 0.7700084447860718\n",
      "Xception Cluster Accuracy     : 0.46756529808044434\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =========================\n",
    "# FINAL COMPARISON\n",
    "# =========================\n",
    "\n",
    "print(\"\\n========== FINAL RESULTS ==========\")\n",
    "print(\"EfficientNet Original Accuracy:\", acc1)\n",
    "print(\"EfficientNet Cluster Accuracy :\", acc2)\n",
    "print(\"Xception Original Accuracy    :\", acc3)\n",
    "print(\"Xception Cluster Accuracy     :\", acc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc432ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
