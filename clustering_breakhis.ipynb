{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bc3736-9a42-4365-9b31-fdf296a81c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn-extra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13564c30-d326-43de-8e34-b92a776aaaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting hdbscan\n",
      "  Downloading hdbscan-0.8.41-cp313-cp313-win_amd64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.20 in c:\\users\\atish\\appdata\\roaming\\python\\python313\\site-packages (from hdbscan) (2.2.5)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\atish\\appdata\\roaming\\python\\python313\\site-packages (from hdbscan) (1.16.3)\n",
      "Requirement already satisfied: scikit-learn>=1.6 in c:\\users\\atish\\appdata\\roaming\\python\\python313\\site-packages (from hdbscan) (1.8.0)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\atish\\appdata\\roaming\\python\\python313\\site-packages (from hdbscan) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\atish\\appdata\\roaming\\python\\python313\\site-packages (from scikit-learn>=1.6->hdbscan) (3.6.0)\n",
      "Downloading hdbscan-0.8.41-cp313-cp313-win_amd64.whl (671 kB)\n",
      "   ---------------------------------------- 0.0/671.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 671.7/671.7 kB 5.5 MB/s eta 0:00:00\n",
      "Installing collected packages: hdbscan\n",
      "Successfully installed hdbscan-0.8.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install hdbscan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df533264-1699-43b1-b857-21196df1b58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-fuzzy\n",
      "  Downloading scikit_fuzzy-0.5.0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading scikit_fuzzy-0.5.0-py2.py3-none-any.whl (920 kB)\n",
      "   ---------------------------------------- 0.0/920.8 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/920.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 920.8/920.8 kB 2.6 MB/s eta 0:00:00\n",
      "Installing collected packages: scikit-fuzzy\n",
      "Successfully installed scikit-fuzzy-0.5.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-fuzzy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "947f6bb4-cfec-4b85-ac74-b0895f5e5e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.cluster import (\n",
    "    KMeans,\n",
    "    MiniBatchKMeans,\n",
    "    AgglomerativeClustering,\n",
    "    SpectralClustering,\n",
    "    MeanShift,\n",
    "    AffinityPropagation,\n",
    "    DBSCAN,\n",
    "    OPTICS,\n",
    "    Birch,\n",
    "    BisectingKMeans\n",
    ")\n",
    "\n",
    "from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "import hdbscan\n",
    "import skfuzzy as fuzz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e58997ba-eb4b-4f12-af6a-8de8f5ebf043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "original_df = pd.read_csv(\"BreaKHis/labels.csv\")\n",
    "\n",
    "image_names = original_df[\"image_name\"].values\n",
    "original_labels = original_df[\"class\"].values\n",
    "\n",
    "le = LabelEncoder()\n",
    "original_labels_enc = le.fit_transform(original_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b360451-97dd-4468-80b2-8b3ad327d130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_label_change(original, clustered):\n",
    "    return (np.sum(original != clustered) / len(original)) * 100\n",
    "\n",
    "\n",
    "def save_cluster_labels_csv(model, algo, image_names, original_labels, labels):\n",
    "    os.makedirs(\"clustering_labels\", exist_ok=True)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"image_name\": image_names,\n",
    "        \"original_label\": original_labels,   # ← human-readable\n",
    "        \"cluster_label\": labels               # ← cluster assignment\n",
    "    })\n",
    "\n",
    "    filename = f\"clustering_labels/{model}_{algo}.csv\"\n",
    "    df.to_csv(filename, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b7bb797-a02e-480f-98bf-5c57c32c55b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_algorithms(X):\n",
    "    \"\"\"\n",
    "    Returns clustering algorithms.\n",
    "    Handles sklearn estimators and callable clustering methods safely.\n",
    "    \"\"\"\n",
    "\n",
    "    # Normalize once for cosine / fuzzy / spherical methods\n",
    "    X_norm = normalize(X)\n",
    "\n",
    "    return {\n",
    "\n",
    "        # ================= PARTITION-BASED =================\n",
    "        \"KMeans\": KMeans(\n",
    "            n_clusters=NUM_CLASSES,\n",
    "            n_init=10,\n",
    "            random_state=42\n",
    "        ),\n",
    "\n",
    "        \"MiniBatchKMeans\": MiniBatchKMeans(\n",
    "            n_clusters=NUM_CLASSES,\n",
    "            n_init=10,\n",
    "            random_state=42\n",
    "        ),\n",
    "\n",
    "        # NOTE: sklearn-extra is unstable with NumPy>=2\n",
    "        # Use only if environment is fixed\n",
    "        \"KMedoids_PAM\": KMedoids(\n",
    "            n_clusters=NUM_CLASSES,\n",
    "            method=\"pam\",\n",
    "            random_state=42\n",
    "        ),\n",
    "\n",
    "        \"BisectingKMeans\": BisectingKMeans(\n",
    "            n_clusters=NUM_CLASSES,\n",
    "            random_state=42\n",
    "        ),\n",
    "\n",
    "        # ================= SPHERICAL / FUZZY =================\n",
    "        # Callable by design (no fit_predict attribute)\n",
    "\n",
    "        \"SphericalKMeans\": lambda X: KMeans(\n",
    "            n_clusters=NUM_CLASSES,\n",
    "            n_init=10,\n",
    "            random_state=42\n",
    "        ).fit_predict(X_norm),\n",
    "\n",
    "        \"FuzzyCMeans\": lambda X: np.argmax(\n",
    "            fuzz.cluster.cmeans(\n",
    "                X_norm.T,\n",
    "                c=NUM_CLASSES,\n",
    "                m=2.0,\n",
    "                error=0.005,\n",
    "                maxiter=1000,\n",
    "                init=None\n",
    "            )[1],\n",
    "            axis=0\n",
    "        ),\n",
    "\n",
    "        # ================= HIERARCHICAL =================\n",
    "        \"Agglomerative_Single\": AgglomerativeClustering(\n",
    "            n_clusters=NUM_CLASSES,\n",
    "            linkage=\"single\"\n",
    "        ),\n",
    "\n",
    "        \"Agglomerative_Complete\": AgglomerativeClustering(\n",
    "            n_clusters=NUM_CLASSES,\n",
    "            linkage=\"complete\"\n",
    "        ),\n",
    "\n",
    "        \"Agglomerative_Average\": AgglomerativeClustering(\n",
    "            n_clusters=NUM_CLASSES,\n",
    "            linkage=\"average\"\n",
    "        ),\n",
    "\n",
    "        # Ward requires Euclidean distance (OK for scaled CNN features)\n",
    "        \"Agglomerative_Ward\": AgglomerativeClustering(\n",
    "            n_clusters=NUM_CLASSES,\n",
    "            linkage=\"ward\"\n",
    "        ),\n",
    "\n",
    "        # ================= DENSITY-BASED =================\n",
    "        # Relaxed eps to avoid single-cluster collapse\n",
    "        \"DBSCAN\": DBSCAN(\n",
    "            eps=0.7,\n",
    "            min_samples=5\n",
    "        ),\n",
    "\n",
    "        \"OPTICS\": OPTICS(\n",
    "            min_samples=5\n",
    "        ),\n",
    "\n",
    "        \"HDBSCAN\": hdbscan.HDBSCAN(\n",
    "            min_cluster_size=max(5, NUM_CLASSES * 2)\n",
    "        ),\n",
    "\n",
    "        # ================= MODEL-BASED =================\n",
    "        # Diagonal covariance + reg for stability\n",
    "        \"GMM\": GaussianMixture(\n",
    "            n_components=NUM_CLASSES,\n",
    "            covariance_type=\"diag\",\n",
    "            reg_covar=1e-3,\n",
    "            max_iter=500,\n",
    "            random_state=42\n",
    "        ),\n",
    "\n",
    "        \"BayesianGMM\": BayesianGaussianMixture(\n",
    "            n_components=NUM_CLASSES,\n",
    "            covariance_type=\"diag\",\n",
    "            reg_covar=1e-3,\n",
    "            max_iter=500,\n",
    "            random_state=42\n",
    "        ),\n",
    "\n",
    "        # ================= LARGE-SCALE =================\n",
    "        \"BIRCH\": Birch(\n",
    "            n_clusters=NUM_CLASSES,\n",
    "            threshold=0.5\n",
    "        ),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "069e40a7-2b35-4bb8-97b9-7108551d20a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f4b7d85-3922-4c18-8ee0-401664f356b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Processing EfficientNetB0 =====\n",
      "→ Implementing KMeans ...\n",
      "   ✓ Done | Label change: 38.25%\n",
      "→ Implementing MiniBatchKMeans ...\n",
      "   ✓ Done | Label change: 83.40%\n",
      "→ Implementing KMedoids_PAM ...\n",
      "   ✓ Done | Label change: 9.55%\n",
      "→ Implementing BisectingKMeans ...\n",
      "   ✓ Done | Label change: 53.51%\n",
      "→ Implementing SphericalKMeans ...\n",
      "   ✓ Done | Label change: 82.54%\n",
      "→ Implementing FuzzyCMeans ...\n",
      "   ✓ Done | Label change: 82.44%\n",
      "→ Implementing Agglomerative_Single ...\n",
      "   ✓ Done | Label change: 68.66%\n",
      "→ Implementing Agglomerative_Complete ...\n",
      "   ✓ Done | Label change: 68.81%\n",
      "→ Implementing Agglomerative_Average ...\n",
      "   ✓ Done | Label change: 69.02%\n",
      "→ Implementing Agglomerative_Ward ...\n",
      "   ✓ Done | Label change: 91.40%\n",
      "→ Implementing DBSCAN ...\n",
      "   ✓ Done | Label change: 86.71%\n",
      "→ Implementing OPTICS ...\n",
      "   ✓ Done | Label change: 99.80%\n",
      "→ Implementing HDBSCAN ...\n",
      "   ✓ Done | Label change: 68.68%\n",
      "→ Implementing GMM ...\n",
      "   ✓ Done | Label change: 79.26%\n",
      "→ Implementing BayesianGMM ...\n",
      "   ✓ Done | Label change: 79.91%\n",
      "→ Implementing BIRCH ...\n",
      "   ✓ Done | Label change: 28.15%\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 2\n",
    "MODEL_NAME = \"EfficientNetB0\"\n",
    "\n",
    "print(f\"\\n===== Processing {MODEL_NAME} =====\")\n",
    "\n",
    "X = np.load(f\"{MODEL_NAME}_features.npy\").astype(np.float64)\n",
    "\n",
    "algorithms = get_algorithms(X)\n",
    "results = []\n",
    "\n",
    "for algo_name, algo in algorithms.items():\n",
    "    print(f\"→ Implementing {algo_name} ...\")\n",
    "\n",
    "    try:\n",
    "        # Case 1: callable algorithms (Fuzzy, Spherical)\n",
    "        if callable(algo):\n",
    "            labels = algo(X)\n",
    "\n",
    "        # Case 2: GMM / BayesianGMM\n",
    "        elif hasattr(algo, \"predict\") and not hasattr(algo, \"fit_predict\"):\n",
    "            algo.fit(X)\n",
    "            labels = algo.predict(X)\n",
    "\n",
    "        # Case 3: sklearn clustering\n",
    "        else:\n",
    "            labels = algo.fit_predict(X)\n",
    "\n",
    "        # Skip degenerate clustering\n",
    "        if len(np.unique(labels)) < 2:\n",
    "            raise ValueError(\"Only one cluster formed\")\n",
    "\n",
    "        save_cluster_labels_csv(\n",
    "            MODEL_NAME,\n",
    "            algo_name,\n",
    "            image_names,\n",
    "            original_labels,\n",
    "            labels\n",
    "        )\n",
    "\n",
    "        change = compute_label_change(original_labels_enc, labels)\n",
    "        results.append([MODEL_NAME, algo_name, change])\n",
    "\n",
    "        print(f\"   ✓ Done | Label change: {change:.2f}%\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ✗ Failed: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "pd.DataFrame(\n",
    "    results,\n",
    "    columns=[\"model\", \"clustering\", \"label_percentage_change\"]\n",
    ").to_csv(\n",
    "    \"clustering_results.csv\",\n",
    "    mode=\"a\",\n",
    "    header=not os.path.exists(\"clustering_results.csv\"),\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00e36386-af6f-4a37-a998-7ba6d2123614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Processing MobileNetV3 =====\n",
      "→ Implementing KMeans ...\n",
      "   ✓ Done | Label change: 70.25%\n",
      "→ Implementing MiniBatchKMeans ...\n",
      "   ✓ Done | Label change: 70.36%\n",
      "→ Implementing KMedoids_PAM ...\n",
      "   ✓ Done | Label change: 69.68%\n",
      "→ Implementing BisectingKMeans ...\n",
      "   ✓ Done | Label change: 73.74%\n",
      "→ Implementing SphericalKMeans ...\n",
      "   ✓ Done | Label change: 69.92%\n",
      "→ Implementing FuzzyCMeans ...\n",
      "   ✓ Done | Label change: 69.77%\n",
      "→ Implementing Agglomerative_Single ...\n",
      "   ✓ Done | Label change: 68.63%\n",
      "→ Implementing Agglomerative_Complete ...\n",
      "   ✓ Done | Label change: 35.31%\n",
      "→ Implementing Agglomerative_Average ...\n",
      "   ✓ Done | Label change: 69.01%\n",
      "→ Implementing Agglomerative_Ward ...\n",
      "   ✓ Done | Label change: 76.61%\n",
      "→ Implementing DBSCAN ...\n",
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing OPTICS ...\n",
      "   ✓ Done | Label change: 99.90%\n",
      "→ Implementing HDBSCAN ...\n",
      "   ✓ Done | Label change: 69.01%\n",
      "→ Implementing GMM ...\n",
      "   ✗ Failed: Only one cluster formed\n",
      "→ Implementing BayesianGMM ...\n",
      "   ✓ Done | Label change: 45.20%\n",
      "→ Implementing BIRCH ...\n",
      "   ✗ Failed: Only one cluster formed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atish\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\mixture\\_base.py:293: ConvergenceWarning: Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
      "  warnings.warn(\n",
      "C:\\Users\\atish\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\cluster\\_birch.py:711: ConvergenceWarning: Number of subclusters found (1) by BIRCH is less than (2). Decrease the threshold.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 2\n",
    "MODEL_NAME = \"MobileNetV3\"\n",
    "\n",
    "print(f\"\\n===== Processing {MODEL_NAME} =====\")\n",
    "\n",
    "X = np.load(f\"{MODEL_NAME}_features.npy\").astype(np.float64)\n",
    "\n",
    "algorithms = get_algorithms(X)\n",
    "results = []\n",
    "\n",
    "for algo_name, algo in algorithms.items():\n",
    "    print(f\"→ Implementing {algo_name} ...\")\n",
    "\n",
    "    try:\n",
    "        # Case 1: callable algorithms (Fuzzy, Spherical)\n",
    "        if callable(algo):\n",
    "            labels = algo(X)\n",
    "\n",
    "        # Case 2: GMM / BayesianGMM\n",
    "        elif hasattr(algo, \"predict\") and not hasattr(algo, \"fit_predict\"):\n",
    "            algo.fit(X)\n",
    "            labels = algo.predict(X)\n",
    "\n",
    "        # Case 3: sklearn clustering\n",
    "        else:\n",
    "            labels = algo.fit_predict(X)\n",
    "\n",
    "        # Skip degenerate clustering\n",
    "        if len(np.unique(labels)) < 2:\n",
    "            raise ValueError(\"Only one cluster formed\")\n",
    "\n",
    "        save_cluster_labels_csv(\n",
    "            MODEL_NAME,\n",
    "            algo_name,\n",
    "            image_names,\n",
    "            original_labels,\n",
    "            labels\n",
    "        )\n",
    "\n",
    "        change = compute_label_change(original_labels_enc, labels)\n",
    "        results.append([MODEL_NAME, algo_name, change])\n",
    "\n",
    "        print(f\"   ✓ Done | Label change: {change:.2f}%\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ✗ Failed: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "\n",
    "pd.DataFrame(\n",
    "    results,\n",
    "    columns=[\"model\", \"clustering\", \"label_percentage_change\"]\n",
    ").to_csv(\n",
    "    \"clustering_results.csv\",\n",
    "    mode=\"a\",\n",
    "    header=not os.path.exists(\"clustering_results.csv\"),\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e640bab-b85f-441b-acc7-6eadf00b19ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Processing Xception =====\n",
      "→ Implementing KMeans ...\n",
      "   ✓ Done | Label change: 94.08%\n",
      "→ Implementing MiniBatchKMeans ...\n",
      "   ✓ Done | Label change: 6.01%\n",
      "→ Implementing KMedoids_PAM ...\n",
      "   ✓ Done | Label change: 93.61%\n",
      "→ Implementing BisectingKMeans ...\n",
      "   ✓ Done | Label change: 5.92%\n",
      "→ Implementing SphericalKMeans ...\n",
      "   ✓ Done | Label change: 90.19%\n",
      "→ Implementing FuzzyCMeans ...\n",
      "   ✓ Done | Label change: 88.91%\n",
      "→ Implementing Agglomerative_Single ...\n",
      "   ✓ Done | Label change: 31.33%\n",
      "→ Implementing Agglomerative_Complete ...\n",
      "   ✓ Done | Label change: 68.76%\n",
      "→ Implementing Agglomerative_Average ...\n",
      "   ✓ Done | Label change: 68.76%\n",
      "→ Implementing Agglomerative_Ward ...\n",
      "   ✓ Done | Label change: 95.73%\n",
      "→ Implementing DBSCAN ...\n",
      "   ✓ Done | Label change: 99.79%\n",
      "→ Implementing OPTICS ...\n",
      "   ✓ Done | Label change: 99.91%\n",
      "→ Implementing HDBSCAN ...\n",
      "   ✓ Done | Label change: 99.94%\n",
      "→ Implementing GMM ...\n",
      "   ✓ Done | Label change: 95.12%\n",
      "→ Implementing BayesianGMM ...\n",
      "   ✓ Done | Label change: 95.35%\n",
      "→ Implementing BIRCH ...\n",
      "   ✓ Done | Label change: 92.45%\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 2\n",
    "MODEL_NAME = \"Xception\"\n",
    "\n",
    "print(f\"\\n===== Processing {MODEL_NAME} =====\")\n",
    "\n",
    "X = np.load(f\"{MODEL_NAME}_features.npy\").astype(np.float64)\n",
    "\n",
    "algorithms = get_algorithms(X)\n",
    "results = []\n",
    "\n",
    "for algo_name, algo in algorithms.items():\n",
    "    print(f\"→ Implementing {algo_name} ...\")\n",
    "\n",
    "    try:\n",
    "        # Case 1: callable algorithms (Fuzzy, Spherical)\n",
    "        if callable(algo):\n",
    "            labels = algo(X)\n",
    "\n",
    "        # Case 2: GMM / BayesianGMM\n",
    "        elif hasattr(algo, \"predict\") and not hasattr(algo, \"fit_predict\"):\n",
    "            algo.fit(X)\n",
    "            labels = algo.predict(X)\n",
    "\n",
    "        # Case 3: sklearn clustering\n",
    "        else:\n",
    "            labels = algo.fit_predict(X)\n",
    "\n",
    "        # Skip degenerate clustering\n",
    "        if len(np.unique(labels)) < 2:\n",
    "            raise ValueError(\"Only one cluster formed\")\n",
    "\n",
    "        save_cluster_labels_csv(\n",
    "            MODEL_NAME,\n",
    "            algo_name,\n",
    "            image_names,\n",
    "            original_labels,\n",
    "            labels\n",
    "        )\n",
    "\n",
    "        change = compute_label_change(original_labels_enc, labels)\n",
    "        results.append([MODEL_NAME, algo_name, change])\n",
    "\n",
    "        print(f\"   ✓ Done | Label change: {change:.2f}%\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ✗ Failed: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "pd.DataFrame(\n",
    "    results,\n",
    "    columns=[\"model\", \"clustering\", \"label_percentage_change\"]\n",
    ").to_csv(\n",
    "    \"clustering_results.csv\",\n",
    "    mode=\"a\",\n",
    "    header=not os.path.exists(\"clustering_results.csv\"),\n",
    "    index=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8667b634-2ae1-4a59-83f9-87913463bf7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a73aa60-cfe9-4cbe-9659-91dd86992dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Change (EfficientNetB0 + KMeans) Silhouette Score: 0.6273\n",
      "Maximum Change (Xception + Birch) Silhouette Score: 0.3694\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# ============================\n",
    "# LOAD FEATURES\n",
    "# ============================\n",
    "\n",
    "X_eff = np.load(\"EfficientNetB0_features.npy\")\n",
    "X_xcep = np.load(\"Xception_features.npy\")\n",
    "\n",
    "# ============================\n",
    "# LOAD CLUSTER LABEL FILES\n",
    "# ============================\n",
    "\n",
    "eff_kmeans_df = pd.read_csv(\"clustering_labels/EfficientNetB0_KMeans.csv\")\n",
    "xcep_birch_df = pd.read_csv(\"clustering_labels/Xception_BIRCH.csv\")\n",
    "\n",
    "labels_eff = eff_kmeans_df[\"cluster_label\"].values\n",
    "labels_xcep = xcep_birch_df[\"cluster_label\"].values\n",
    "\n",
    "# ============================\n",
    "# REMOVE NOISE IF PRESENT (-1)\n",
    "# ============================\n",
    "\n",
    "def compute_silhouette(X, labels, name):\n",
    "    unique_labels = np.unique(labels)\n",
    "\n",
    "    if len(unique_labels) < 2:\n",
    "        print(f\"{name}: Cannot compute silhouette (only one cluster)\")\n",
    "        return None\n",
    "\n",
    "    # Remove noise label -1 if exists\n",
    "    mask = labels != -1\n",
    "    X_clean = X[mask]\n",
    "    labels_clean = labels[mask]\n",
    "\n",
    "    if len(np.unique(labels_clean)) < 2:\n",
    "        print(f\"{name}: Not enough valid clusters after removing noise\")\n",
    "        return None\n",
    "\n",
    "    score = silhouette_score(X_clean, labels_clean)\n",
    "    print(f\"{name} Silhouette Score: {score:.4f}\")\n",
    "    return score\n",
    "\n",
    "\n",
    "# ============================\n",
    "# COMPUTE SCORES\n",
    "# ============================\n",
    "\n",
    "score_min = compute_silhouette(\n",
    "    X_eff,\n",
    "    labels_eff,\n",
    "    \"Minimum Change (EfficientNetB0 + KMeans)\"\n",
    ")\n",
    "\n",
    "score_max = compute_silhouette(\n",
    "    X_xcep,\n",
    "    labels_xcep,\n",
    "    \"Maximum Change (Xception + Birch)\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a93530-4ac6-496a-99e4-c1694ce0e02c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
