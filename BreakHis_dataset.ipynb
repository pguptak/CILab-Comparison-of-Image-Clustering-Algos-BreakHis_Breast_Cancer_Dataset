{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2dcf7c7-49f7-40a8-8763-776cef54397e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset extracted and ready for use\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "ZIP_PATH = \"BreakHis.zip\"\n",
    "EXTRACT_PATH = \"BreakHis\"\n",
    "\n",
    "if not os.path.exists(EXTRACT_PATH):\n",
    "    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
    "        zip_ref.extractall(EXTRACT_PATH)\n",
    "\n",
    "print(\"Dataset extracted and ready for use\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2efb311b-b6de-487f-bf49-c252789aa075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset path:\n",
      "BreakHis\\BreaKHis_v1\\BreaKHis_v1\\histology_slides\\breast\n",
      "\n",
      "Mixed images path:\n",
      "BreakHis\\mixed_images\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "\n",
    "# Base working directory\n",
    "BASE_DIR = \"BreakHis\"\n",
    "\n",
    "# Path to the original dataset\n",
    "original_dataset= os.path.join(\n",
    "    BASE_DIR,\n",
    "    \"BreaKHis_v1\",\n",
    "    \"BreaKHis_v1\",\n",
    "    \"histology_slides\",\n",
    "    \"breast\"\n",
    ")\n",
    "\n",
    "# Path where mixed images will be stored\n",
    "images= os.path.join(BASE_DIR, \"mixed_images\")\n",
    "\n",
    "# Create mixed_images directory if it does not exist\n",
    "os.makedirs(images, exist_ok=True)\n",
    "\n",
    "print(\"Original dataset path:\")\n",
    "print(original_dataset)\n",
    "\n",
    "print(\"\\nMixed images path:\")\n",
    "print(images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "079a68e8-89d1-46cc-bf16-a12eae4713a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_records = []\n",
    "image_counter = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for class_name in sorted(os.listdir(original_dataset)):  # benign / malignant\n",
    "    class_path = os.path.join(original_dataset, class_name)\n",
    "\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "\n",
    "    for protocol in sorted(os.listdir(class_path)):  # SOB\n",
    "        protocol_path = os.path.join(class_path, protocol)\n",
    "\n",
    "        if not os.path.isdir(protocol_path):\n",
    "            continue\n",
    "\n",
    "        for tumor_type in sorted(os.listdir(protocol_path)):  # adenosis, ductal_carcinoma\n",
    "            tumor_type_path = os.path.join(protocol_path, tumor_type)\n",
    "\n",
    "            if not os.path.isdir(tumor_type_path):\n",
    "                continue\n",
    "\n",
    "            for patient_folder in sorted(os.listdir(tumor_type_path)):  # SOB_B_A_xxxx\n",
    "                patient_path = os.path.join(tumor_type_path, patient_folder)\n",
    "\n",
    "                if not os.path.isdir(patient_path):\n",
    "                    continue\n",
    "\n",
    "                for magnification in sorted(os.listdir(patient_path)):  # 40X,100X,...\n",
    "                    magnification_path = os.path.join(patient_path, magnification)\n",
    "\n",
    "                    if not os.path.isdir(magnification_path):\n",
    "                        continue\n",
    "\n",
    "                    for image_name in sorted(os.listdir(magnification_path)):\n",
    "                        if image_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                            image_counter += 1\n",
    "                            new_image_name = f\"img_{image_counter:06d}.png\"\n",
    "\n",
    "                            src_path = os.path.join(magnification_path, image_name)\n",
    "                            dst_path = os.path.join(images, new_image_name)\n",
    "\n",
    "                            shutil.copy(src_path, dst_path)\n",
    "\n",
    "                            image_records.append({\n",
    "                                \"image_name\": new_image_name,\n",
    "                                \"class\": class_name,         # benign / malignant\n",
    "                                \"tumor_type\": tumor_type,    # adenosis, DC, LC, etc\n",
    "                                \"magnification\": magnification\n",
    "                            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d635112d-cd07-4a2c-92a4-f65566bd0688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images copied: 7909\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrame from image records\n",
    "labels_df = pd.DataFrame(image_records)\n",
    "\n",
    "# Save labels CSV inside the working dataset folder\n",
    "labels_csv_path = os.path.join(\"BreakHis\", \"labels.csv\")\n",
    "labels_df.to_csv(labels_csv_path, index=False)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Total images copied: {image_counter}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94f24af4-a905-4f8f-9136-ab2871ff3218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e199fc9a-5e2c-45d4-9ed1-d95c48985fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>class</th>\n",
       "      <th>tumor_type</th>\n",
       "      <th>magnification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_000001.png</td>\n",
       "      <td>benign</td>\n",
       "      <td>adenosis</td>\n",
       "      <td>100X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_000002.png</td>\n",
       "      <td>benign</td>\n",
       "      <td>adenosis</td>\n",
       "      <td>100X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_000003.png</td>\n",
       "      <td>benign</td>\n",
       "      <td>adenosis</td>\n",
       "      <td>100X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_000004.png</td>\n",
       "      <td>benign</td>\n",
       "      <td>adenosis</td>\n",
       "      <td>100X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_000005.png</td>\n",
       "      <td>benign</td>\n",
       "      <td>adenosis</td>\n",
       "      <td>100X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_name   class tumor_type magnification\n",
       "0  img_000001.png  benign   adenosis          100X\n",
       "1  img_000002.png  benign   adenosis          100X\n",
       "2  img_000003.png  benign   adenosis          100X\n",
       "3  img_000004.png  benign   adenosis          100X\n",
       "4  img_000005.png  benign   adenosis          100X"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = pd.read_csv(labels_csv_path)\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34d5676c-1639-4c19-a142-a6a7ad3abfa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    5429\n",
       "0    2480\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = {\"benign\": 0, \"malignant\": 1}\n",
    "labels_df[\"label\"] = labels_df[\"class\"].map(label_map)\n",
    "\n",
    "labels_df[\"label\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "773d44a6-363e-495a-9c56-91deaccef970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: np.float64(1.5945564516129032), 1: np.float64(0.7284030208141462)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "class_weights_array = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.array([0, 1]),\n",
    "    y=labels_df[\"label\"].values\n",
    ")\n",
    "\n",
    "class_weights = {\n",
    "    0: class_weights_array[0],  # benign\n",
    "    1: class_weights_array[1]   # malignant\n",
    "}\n",
    "\n",
    "print(\"Class weights:\", class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5223d8e2-e12b-46ea-bf97-f6c04a6cb752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_df, val_df = train_test_split(\n",
    "#     labels_df,\n",
    "#     test_size=0.2,\n",
    "#     stratify=labels_df[\"label\"],\n",
    "#     random_state=42\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f6e303-e1d0-45ce-9cb0-36d6cbb9865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 16\n",
    "IMAGES_DIR = \"BreakHis/mixed_images\"\n",
    "\n",
    "def load_image(path, label):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = tf.image.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    return img, label\n",
    "\n",
    "\n",
    "def build_dataset(df, shuffle=True):\n",
    "    paths = df[\"image_name\"].apply(\n",
    "        lambda x: os.path.join(IMAGES_DIR, x)\n",
    "    ).values\n",
    "\n",
    "    labels = df[\"label\"].values.astype(np.int32)\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    ds = ds.map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=1000)\n",
    "\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28eb80f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = build_dataset(train_df, shuffle=True)\n",
    "val_ds   = build_dataset(val_df, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be1a2a45-1d61-4685-8269-5a66ccbc19cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet152\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_resnet152():\n",
    "    base = ResNet152(\n",
    "        include_top=False,\n",
    "        weights=None,\n",
    "        input_shape=(224,224,3)\n",
    "    )\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(base.output)\n",
    "    features = layers.Dense(256, activation=\"relu\", name=\"feature_vector\")(x)\n",
    "    output = layers.Dense(2, activation=\"softmax\")(features)\n",
    "\n",
    "    model = models.Model(base.input, output)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4635446a-ea68-4fe7-8074-395b3542d7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG19\n",
    "\n",
    "def build_vgg19():\n",
    "    base = VGG19(\n",
    "        include_top=False,\n",
    "        weights=None,\n",
    "        input_shape=(224,224,3)\n",
    "    )\n",
    "\n",
    "    x = layers.Flatten()(base.output)\n",
    "    features = layers.Dense(256, activation=\"relu\", name=\"feature_vector\")(x)\n",
    "    output = layers.Dense(2, activation=\"softmax\")(features)\n",
    "\n",
    "    model = models.Model(base.input, output)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dea7fd94-d7ab-477b-a68c-a9e1cf98c714",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import Xception\n",
    "\n",
    "def build_xception():\n",
    "    base = Xception(\n",
    "        include_top=False,\n",
    "        weights=None,\n",
    "        input_shape=(224,224,3)\n",
    "    )\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(base.output)\n",
    "    features = layers.Dense(256, activation=\"relu\", name=\"feature_vector\")(x)\n",
    "    output = layers.Dense(2, activation=\"softmax\")(features)\n",
    "\n",
    "    model = models.Model(base.input, output)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ea1933-26b3-47ec-a7f5-ee96005f1565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def build_efficientnetb0():\n",
    "    base = EfficientNetB0(\n",
    "        include_top=False,\n",
    "        weights=None,\n",
    "        input_shape=(224, 224, 3)\n",
    "    )\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(base.output)\n",
    "    features = layers.Dense(\n",
    "        256, activation=\"relu\", name=\"feature_vector\"\n",
    "    )(x)\n",
    "    output = layers.Dense(2, activation=\"softmax\")(features)\n",
    "\n",
    "    model = models.Model(base.input, output)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "580ea0a1-b614-404b-97c0-fb110cf4f76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV3Large\n",
    "\n",
    "def build_mobilenetv3():\n",
    "    base = MobileNetV3Large(\n",
    "        include_top=False,\n",
    "        weights=None,\n",
    "        input_shape=(224,224,3)\n",
    "    )\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(base.output)\n",
    "    features = layers.Dense(256, activation=\"relu\", name=\"feature_vector\")(x)\n",
    "    output = layers.Dense(2, activation=\"softmax\")(features)\n",
    "\n",
    "    model = models.Model(base.input, output)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d0685d9-d2b1-4a36-9979-9be6ab63f03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def train_model(model, name):\n",
    "    print(f\"\\nTraining {name}\")\n",
    "    model.compile(\n",
    "        optimizer=Adam(1e-4),\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    model.summary()  # REQUIRED by instructions\n",
    "\n",
    "    model.fit(\n",
    "        train_ds,\n",
    "        validation_data=val_ds,\n",
    "        epochs=10,\n",
    "        class_weight=class_weights\n",
    "    )\n",
    "\n",
    "    feature_extractor = tf.keras.Model(\n",
    "        inputs=model.input,\n",
    "        outputs=model.get_layer(\"feature_vector\").output\n",
    "    )\n",
    "\n",
    "    return feature_extractor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ea0655-c405-46cc-8588-827220095c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractors = {}\n",
    "\n",
    "feature_extractors[\"ResNet152\"]  = train_model(build_resnet152(), \"ResNet152\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc68baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractors[\"EfficientNetB0\"]    = train_model(build_efficientnetb0(), \"EfficientNetB0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2b58b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractors[\"VGG19\"]      = train_model(build_vgg19(), \"VGG19\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd82f2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractors[\"Xception\"]   = train_model(build_xception(), \"Xception\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ae133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractors[\"MobileNetV3\"]= train_model(build_mobilenetv3(), \"MobileNetV3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eee164-1e0c-4db2-bf0c-56c89ffb13a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ds = build_dataset(labels_df, shuffle=False)\n",
    "\n",
    "FEATURE_DIR = \"saved_features\"\n",
    "os.makedirs(FEATURE_DIR, exist_ok=True)\n",
    "\n",
    "feature_vectors = {}\n",
    "\n",
    "for name, extractor in feature_extractors.items():\n",
    "    features = extractor.predict(full_ds)\n",
    "    feature_vectors[name] = features\n",
    "\n",
    "    np.save(\n",
    "        os.path.join(FEATURE_DIR, f\"{name}_features.npy\"),\n",
    "        features\n",
    "    )\n",
    "\n",
    "    print(f\"✅ {name} features saved:\", features.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52e7b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b9f48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kmeans_and_label_change(features, true_labels, k=2):\n",
    "    \"\"\"\n",
    "    features     : feature matrix (N x D)\n",
    "    true_labels  : ground-truth labels (0/1)\n",
    "    k            : number of clusters\n",
    "    \"\"\"\n",
    "\n",
    "    # Normalize features (VERY IMPORTANT for K-Means)\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "\n",
    "    from sklearn.decomposition import PCA\n",
    "\n",
    "    pca = PCA(n_components=0.95, random_state=42)  # keep 95% variance\n",
    "    features_pca = pca.fit_transform(features_scaled)\n",
    "\n",
    "    print(\"Original dim:\", features.shape[1])\n",
    "    print(\"Reduced dim:\", features_pca.shape[1])\n",
    "\n",
    "\n",
    "    # Apply K-Means\n",
    "    kmeans = KMeans(\n",
    "        n_clusters=k,\n",
    "        random_state=42,\n",
    "        n_init=10\n",
    "    )\n",
    "    cluster_labels = kmeans.fit_predict(features_pca)\n",
    "\n",
    "    # Because cluster IDs are arbitrary, align clusters to true labels\n",
    "    df_temp = pd.DataFrame({\n",
    "        \"true\": true_labels,\n",
    "        \"cluster\": cluster_labels\n",
    "    })\n",
    "\n",
    "    mapping = {}\n",
    "    for c in np.unique(cluster_labels):\n",
    "        majority_label = df_temp[df_temp[\"cluster\"] == c][\"true\"].mode()[0]\n",
    "        mapping[c] = majority_label\n",
    "\n",
    "    mapped_clusters = np.array([mapping[c] for c in cluster_labels])\n",
    "\n",
    "    # Label change calculation\n",
    "    changed = mapped_clusters != true_labels\n",
    "    change_percentage = changed.mean() * 100\n",
    "\n",
    "    return change_percentage, changed, mapped_clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca247524",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "\n",
    "true_labels = labels_df[\"label\"].values\n",
    "\n",
    "import os, numpy as np\n",
    "\n",
    "LABEL_DIR = \"saved_labels\"\n",
    "os.makedirs(LABEL_DIR, exist_ok=True)\n",
    "\n",
    "np.save(os.path.join(LABEL_DIR, \"true_labels.npy\"), true_labels)\n",
    "print(\"✅ True labels saved for future clustering\")\n",
    "\n",
    "\n",
    "for model_name, features in feature_vectors.items():\n",
    "    change_pct, changed_flags, mapped_clusters = run_kmeans_and_label_change(\n",
    "        features,\n",
    "        true_labels,\n",
    "        k=2\n",
    "    )\n",
    "\n",
    "    results[model_name] = {\n",
    "        \"change_percentage\": change_pct,\n",
    "        \"changed_flags\": changed_flags,\n",
    "        \"mapped_clusters\": mapped_clusters\n",
    "    }\n",
    "\n",
    "    print(f\"{model_name} → Label change percentage: {change_pct:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d63970",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = pd.DataFrame({\n",
    "    \"Model\": results.keys(),\n",
    "    \"Label Change (%)\": [results[m][\"change_percentage\"] for m in results]\n",
    "})\n",
    "\n",
    "summary_df.sort_values(\"Label Change (%)\")\n",
    "summary_df.to_csv(\"model_comparison_label_change.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
